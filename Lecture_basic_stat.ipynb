{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 통계량 구하기  \n",
    "\n",
    "- 분포(distribution)와 관계없는 통계량\n",
    "    - (단순)평균; (arithmetic)mean  \n",
    "    $ \n",
    "\\begin{align} \n",
    "    \\bar{X} \\, or \\, E[X]  &= \\frac{1}{n} (X_1 + X_2 + \\cdots + X_n) \\nonumber \\\\\n",
    "     &= \\frac{1}{n} \\sum_{i=1}^{n} X_i \\nonumber  \n",
    "\\end{align}\n",
    "$\n",
    "    - 분산; variance  \n",
    "        $ \\begin{align} \n",
    "            \\sigma_X^2 \\, or \\, Var(X) &= E[(X-E[X])^2] \\nonumber \\\\\n",
    "            &= \\frac{1}{n} \\sum_{i=1}^{n} (X_i - E[X])^2 \\nonumber\n",
    "        \\end{align} $\n",
    "          \n",
    "        [Unbiased sample variance](https://en.wikipedia.org/wiki/Variance#Unbiased_sample_variance):  \n",
    "        $ \\begin{align} \n",
    "            s_X^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - E[X])^2 \\nonumber\n",
    "        \\end{align} $\n",
    "\n",
    "\n",
    "    - 표준편차; standard deviation (unbiased)  \n",
    "        $ \\begin{align} \n",
    "            s_X &= \\sqrt{s_X^2} \\nonumber\n",
    "        \\end{align} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (단순)평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.5 + 3.2 + 5.8 + 7.1 + 2.4 + 4.9 + 6.5 + 8.2 + 0.9) / 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[np.mean()](https://numpy.org/doc/stable/reference/generated/numpy.mean.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "data = np.array([1.5, 3.2, 5.8, 7.1, 2.4, 4.9, 6.5, 8.2, 0.9])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 갯수\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균값\n",
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대값 최소값\n",
    "print(np.max(data), np.min(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[np.nanmean()](https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html) 결측값을 무시함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12개 요소를 가진 샘플 데이터 생성, 일부 값은 NaN으로 설정\n",
    "# NaN은 missing value (결측값)\n",
    "data_missing = np.array([1.5, 3.2, np.nan, 5.8, 7.1, np.nan, 2.4, 4.9, 6.5, 8.2, 0.9, np.nan])\n",
    "data_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(), max(), min()은 결측값이 있는 경우, 제대로 동작하지 않음\n",
    "print(np.max(data_missing), np.min(data_missing))\n",
    "np.mean(data_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.nanmean()은 오류없이 결측값을 무시한 값을 출력\n",
    "np.nanmean(data_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.nanmax()와 nanmin()역시 결측값을 무시한 값을 출력\n",
    "print(np.nanmax(data_missing), np.nanmin(data_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len()함수는 결측값도 세아리기 때문에 인덱스를 사용하여야 함\n",
    "print(len(data_missing))\n",
    "len(data_missing[~np.isnan(data_missing)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (1.5 + 3.2 + 5.8 + 7.1 + 2.4 + 4.9 + 6.5 + 8.2 + 0.9) / 9\n",
    "((1.5-mean)**2 + (3.2-mean)**2 + (5.8-mean)**2 + (7.1-mean)**2 + (2.4-mean)**2 + (4.9-mean)**2 + (6.5-mean)**2 + (8.2-mean)**2 + (0.9-mean)**2) / 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[np.var()](https://numpy.org/doc/stable/reference/generated/numpy.var.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 분산\n",
    "np.var(data, \n",
    "        # 자유도 조정\n",
    "        ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(data_missing, \n",
    "        # 자유도 조정\n",
    "        ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[np.nanvar()](https://numpy.org/doc/stable/reference/generated/numpy.nanvar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN 값을 무시하고 분산 계산\n",
    "np.nanvar(data_missing, \n",
    "            # 자유도 조정\n",
    "            ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자유도 조정을 하지 않는다면?\n",
    "print('DoF adjusted',np.nanvar(data_missing, \n",
    "            # 자유도 조정\n",
    "            ddof=1),\n",
    "       '\\nDoF not adjusted',\n",
    "        np.nanvar(data_missing, \n",
    "            # 자유도 조정\n",
    "            ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표준편차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[np.std()](https://numpy.org/doc/stable/reference/generated/numpy.std.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 표준편차\n",
    "np.std(data,\n",
    "        # 자유도 조정\n",
    "        ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(data_missing,\n",
    "        # 자유도 조정\n",
    "        ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[np.nanstd()](https://numpy.org/doc/stable/reference/generated/numpy.nanstd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN 값을 무시하고 표준편차 계산\n",
    "np.nanstd(data_missing,\n",
    "            # 자유도 조정\n",
    "            ddof=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자유도 조정을 하지 않는다면?\n",
    "print('DoF adjusted',np.nanstd(data_missing, \n",
    "            # 자유도 조정\n",
    "            ddof=1),\n",
    "       '\\nDoF not adjusted',\n",
    "        np.nanstd(data_missing, \n",
    "            # 자유도 조정\n",
    "            ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불러온 데이터의 기초통계량\n",
    "1978년 CPS (Current Population Survey)데이터  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 소수점 설정\n",
    "pd.options.display.float_format = \"{:,.1f}\".format\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df_cps = pd.read_csv(r'https://raw.githubusercontent.com/SeanJSLee/Teaching_YU_DS_basic_KR/main/data/Dehejia_and_Wahba_1999/data_cps78_income.csv')\n",
    "# df_cps = df_cps.loc[df_cps['date'] == '2023-03-01'].reset_index(drop=True)\n",
    "print('CPS 1978 data: https://github.com/SeanJSLee/Teaching_YU_DS_basic_KR/blob/main/data/Dehejia_and_Wahba_1999/data_cps78_income.csv \\n',df_cps.dtypes)\n",
    "df_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임금평균 - 1978 raw 데이터\n",
    "np.mean(df_cps['income_78'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임금 표준편차 - 1978 raw 데이터\n",
    "np.std(df_cps['income_78'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규분포와 쌍둥이들 - 자연스러운 확률?!\n",
    "- (거의) 모든것이 정규분포가 된다? 중심극한정리; the central limit theorem  \n",
    "[![3b1b_clt](https://i.ytimg.com/an_webp/SoKjCUcDBf0/mqdefault_6s.webp?du=3000&sqp=CImfwa8G&rs=AOn4CLCyCJ_NyBmIDv_PIv-mhxoD2Xw4Sg)](https://www.youtube.com/watch?v=SoKjCUcDBf0)  \n",
    "- 정규분포  \n",
    "[![statquest_normal](https://i.ytimg.com/vi/rzFX5NWojp0/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCKnTAtZLuIfqY6Rp_SaAAWLvpFig)](https://www.youtube.com/watch?v=rzFX5NWojp0&t=13)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정규분포에서 평균과 분산의 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_dist_draw(distributions):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import scipy.stats as stats\n",
    "    # Generate x values\n",
    "    x = np.linspace(-7, 7, 1000)\n",
    "    # Plot each distribution\n",
    "    for dist in distributions:\n",
    "        y = stats.norm.pdf(x, dist['mean'], dist['std'])\n",
    "        plt.plot(x, y, label=f\"{dist['label']}\")\n",
    "    # Adding labels and legend\n",
    "    plt.axvline(x=0, color='k', linestyle='--', label='x=0')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title('Multiple Normal Distributions')\n",
    "    plt.legend()\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "# \n",
    "\n",
    "distributions = [\n",
    "    {'mean': 0, 'std': 1, 'label': 'μ=0, σ=1'},\n",
    "    {'mean': 0, 'std': 2, 'label': 'μ=0, σ=2'},\n",
    "    {'mean': -2, 'std': 1, 'label': 'μ=-2, σ=1'},\n",
    "    {'mean': 2, 'std': 0.5, 'label': 'μ=2, σ=0.5'}\n",
    "]\n",
    "normal_dist_draw(distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 표준정규분포화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = [\n",
    "    {'mean': 0, 'std': 1, 'label': 'μ=0, σ=1; Standard normal'},\n",
    "    {'mean': 0.75, 'std': 0.9, 'label': 'μ=0.75, σ=0.9'},\n",
    "    {'mean': 1.5, 'std': 0.7, 'label': 'μ=1.5, σ=0.7'},\n",
    "    {'mean': 2, 'std': 0.5, 'label': 'μ=2, σ=0.5'}\n",
    "]\n",
    "\n",
    "normal_dist_draw(distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 표준정규분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cv_conf(alpha):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import scipy.stats as stats\n",
    "    # Standard normal distribution parameters\n",
    "    mu = 0  # mean\n",
    "    sigma = 1  # standard deviation\n",
    "    # Create a range of x values\n",
    "    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
    "    # The y values corresponding to the standard normal pdf\n",
    "    y = stats.norm.pdf(x, mu, sigma)\n",
    "    # Plot the standard normal distribution\n",
    "    plt.plot(x, y, label='Standard Normal Distribution')\n",
    "    # Critical values for two-tailed test at alpha level\n",
    "    critical_value_right = stats.norm.ppf(1 - alpha / 2)\n",
    "    critical_value_left = stats.norm.ppf(alpha / 2)\n",
    "    # Plot the critical values\n",
    "    plt.axvline(critical_value_right, color='r', linestyle='--', label='Critical Value (Right Tail)')\n",
    "    plt.axvline(critical_value_left, color='g', linestyle='--', label='Critical Value (Left Tail)')\n",
    "    # Labeling the critical values\n",
    "    plt.text(critical_value_right, 0.1, f'{critical_value_right:.2f}', horizontalalignment='center', color='red')\n",
    "    plt.text(critical_value_left, 0.1, f'{critical_value_left:.2f}', horizontalalignment='center', color='green')\n",
    "    # Fill between for the two-tail areas\n",
    "    plt.fill_between(x, y, where=(x > critical_value_left) & (x < critical_value_right), color='blue', alpha=0.5, label=f'{(1-alpha):.00%} data')\n",
    "    # Additional plot formatting\n",
    "    plt.xlabel('z')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title('Standard Normal Distribution with Two-Tail Test (α={alpha})'.format(alpha=alpha))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "# \n",
    "\n",
    "draw_cv_conf(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cv_conf(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cv_conf(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 표준정규분포를 이용해서 정규분포의 신뢰구간 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_standardization(data, alpha) :\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import scipy.stats as stats\n",
    "    mu = np.nanmean(data)\n",
    "    sigma = np.nanstd(data)\n",
    "    n = len(data[~np.isnan(data)])\n",
    "    # Alpha level for two-tailed test\n",
    "    # alpha = 0.05\n",
    "    # \n",
    "    fig, axe = plt.subplots(2,1, figsize=(8,8))\n",
    "    # ax = plt.hist((data-np.mean(data))/np.std(data), bins=round(np.sqrt(n)), density=True, alpha=0.8)\n",
    "    for idx, ax in enumerate(axe) :\n",
    "        # print(idx)\n",
    "        if idx == 0 :\n",
    "            ax.hist(data, bins=min(round(np.sqrt(n)),50), density=True, alpha=0.8)\n",
    "        elif idx == 1 :\n",
    "            mu = np.mean((data-np.mean(data))/np.std(data))  # Mean\n",
    "            sigma = np.std((data-np.mean(data))/np.std(data))  # Standard deviation\n",
    "        else :\n",
    "            continue\n",
    "        # Parameters for the standard normal distribution\n",
    "        # Generate points on the x axis between -4 and 4:\n",
    "        x = np.linspace((mu-3*sigma), (mu+3*sigma), 1000)\n",
    "        # Calculate the normal distribution's PDF at these points:\n",
    "        y = stats.norm.pdf(x, mu, sigma)\n",
    "        ax.plot(x, y)\n",
    "        # Critical values for two-tailed test at alpha level\n",
    "        critical_value_right = mu + stats.norm.ppf(1 - alpha / 2) * sigma\n",
    "        critical_value_left  = mu + stats.norm.ppf(alpha / 2) * sigma\n",
    "        # Plot the critical values\n",
    "        ax.axvline(critical_value_right, color='r', linestyle='--', label='Critical Value (Right Tail)')\n",
    "        ax.axvline(critical_value_left, color='g', linestyle='--', label='Critical Value (Left Tail)')\n",
    "        # Labeling the critical values\n",
    "        ax.text(critical_value_right, 0.1, f'{critical_value_right:.2f}', horizontalalignment='center', color='red')\n",
    "        ax.text(critical_value_left, 0.1, f'{critical_value_left:.2f}', horizontalalignment='center', color='green')\n",
    "        # Fill between for the two-tail areas\n",
    "        ax.fill_between(x, y, where=(x > critical_value_left) & (x < critical_value_right), \n",
    "        color='blue', alpha=0.5, label=f'{(1-alpha):.00%} data')\n",
    "        if idx == 0 :\n",
    "            print(f'Total observation:{n} \\n95% observation are in [{critical_value_left:.2f}, {critical_value_right:.2f}] \\n\\tnumber of observation: {len(data[(data>=critical_value_left)&(data<=critical_value_right)])}, {len(data[(data>=critical_value_left)&(data<=critical_value_right)])/len(data):.2%}')\n",
    "    plt.xlabel('z')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title('Standard Normal Distribution with Two-Tail Test (α={alpha})'.format(alpha=alpha))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mu = 6  # Mean\n",
    "sigma = 1  # Standard deviation\n",
    "n = 1000\n",
    "alpha = 0.05\n",
    "data = np.random.normal(loc=mu, scale=sigma,size=n)\n",
    "draw_standardization(data, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 10  # Mean\n",
    "sigma = 1  # Standard deviation\n",
    "n = 1000\n",
    "alpha = 0.1\n",
    "data = np.random.normal(loc=mu, scale=sigma,size=n)\n",
    "draw_standardization(data, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Confidence interval (신뢰구간)  \n",
    "\n",
    "Student's t 분포\n",
    "![t-stat](https://www.scribbr.com/wp-content/uploads/2020/08/diff_scores_ci.png)\n",
    "\n",
    "\n",
    "$ [E[X] - {critical \\, value}_{\\alpha=0.975}  \\frac{\\sigma_X}{\\sqrt{obs}}, \\quad E[X] + {critical \\, value}_{\\alpha=0.975}  \\frac{\\sigma_X}{\\sqrt{obs}}] $ -->\n",
    "\n",
    "<!-- import scipy.stats as st\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(\n",
    "    # 유의수준\n",
    "    confidence=0.90, \n",
    "    # 자유도 = N-1\n",
    "    df=len(data[~np.isnan(data)])-1, \n",
    "    # 평균\n",
    "    loc=np.nanmean(data), \n",
    "    # 표준편차\n",
    "    scale=np.nanstd(data)) \n",
    "st.t.ppf(0.1, len(data[~np.isnan(data)])-1) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터의 분포확인하기 - 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 소수점 설정\n",
    "pd.options.display.float_format = \"{:,.1f}\".format\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df_cps = pd.read_csv(r'https://raw.githubusercontent.com/SeanJSLee/Teaching_YU_DS_basic_KR/main/data/Dehejia_and_Wahba_1999/data_cps78_income.csv')\n",
    "# df_cps = df_cps.loc[df_cps['date'] == '2023-03-01'].reset_index(drop=True)\n",
    "print('CPS 1978 data: https://github.com/SeanJSLee/Teaching_YU_DS_basic_KR/blob/main/data/Dehejia_and_Wahba_1999/data_cps78_income.csv \\n',df_cps.dtypes)\n",
    "df_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(np.log(df_cps['income_78']), bins=30, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 소수점 설정\n",
    "pd.options.display.float_format = \"{:,.1f}\".format\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df_hps = pd.read_csv(r'https://raw.githubusercontent.com/SeanJSLee/Teaching_YU_DS_basic_KR/main/data/KOSIS_houshold_panel_survey/data_income_kor.csv')\n",
    "df_hps = df_hps.loc[df_hps['date'] == '2023-03-01'].reset_index(drop=True)\n",
    "print(df_hps.dtypes)\n",
    "df_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(df_hps['income'], bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(df_hps['income'].loc[df_hps['income']<25000000], bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(df_hps['ln_income'], bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_standardization(df_hps['ln_income'], alpha=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
